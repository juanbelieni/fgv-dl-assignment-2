{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4ssIFK7m1cOg"
      },
      "source": [
        "# **Homework 2 - Semantic Segmentation**\n",
        "\n",
        "Objective: Implement a U-Net Network for semantic segmentation.\n",
        "\n",
        "\n",
        "\n",
        "Dataset:\n",
        "\n",
        "<figure>\n",
        "<center>\n",
        "<img src= 'https://raw.githubusercontent.com/mabelortega/DL_Semantic_Segmentation/main/Figures/drawing1.png'/>\n",
        "</figure>\n",
        "\n",
        "You must train the network model by using these images [https://drive.google.com/file/d/1TU2nTVGS2932hRs1u-ma4r3vmgqHRbMO/view?usp=sharing]. Image_Train.tif and Reference_Train.tif images and it must be evaluated on Image_Test.tif and Reference_Test.tif images. You can use this notebook that contains some basic functions.\n",
        "\n",
        "Experimental Protocol\n",
        "\n",
        "Load the input data\n",
        "1.     Load the images provided from 2D Semantic Labeling-Vaihingen dataset using the function load_tiff_image(image) and normalize the data into the range [0,1] using the function normalization (image)\n",
        "\n",
        "Train the FCN model\n",
        "2.     To train the FCN model you need patches as input. You must extract patches of size w-by-w-by-c pixels from Image_Train and patches with size w-by-w from Reference_Train. The number of patches and the w must be chosen based on the input size of network.\n",
        "\n",
        "3.     Split randomly the training patches into two sets: Training (80%) and validation (20%).\n",
        "\n",
        "4.     Convert the patches of the Reference image into one-hot encoding base on the number of classes. Hint: Use the function tf.keras.utils.to_categorical.\n",
        "\n",
        "5.     Create the function of the U-Net model - Using skip connections: Hint: use tensorflow.keras.layers.concatenate\n",
        "\n",
        "6.     For training, use the weighted_categorical_crossentropy as a loss function. Hint: To compute the weights you must count the number of pixels of each class and apply the formula: w_i = #total_pixels / #pixels_of_class_i\n",
        "\n",
        "\n",
        "\n",
        "7.     Train the model using Train_model() function, which has as input the training and validation patches. You must the best model adding the early stop strategy with patience equal to 10.\n",
        "\n",
        "8.     Extract patches from the test images and test the model using Test(model, patch_test).\n",
        "\n",
        "9.     Reconstruct the prediction (whole test image)\n",
        "\n",
        "The report must present the classification results as label images, and report accuracy metrics (overall and average class accuracies, F1-score) you also must change the size of the extracted patches to compare the results (32x32, 64x64, 128x128)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MGhOgDtM9W8c"
      },
      "source": [
        "# **Import the libraries**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "xE6yP1WF9KlA"
      },
      "outputs": [],
      "source": [
        "import keras.backend as K\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from keras import Model\n",
        "from keras.layers import Conv2D, Input, MaxPool2D, UpSampling2D, Conv2DTranspose, concatenate\n",
        "from keras.optimizers import Adam\n",
        "from PIL import Image\n",
        "from sklearn.metrics import (\n",
        "    accuracy_score,\n",
        "    confusion_matrix,\n",
        "    f1_score,\n",
        "    precision_score,\n",
        "    recall_score,\n",
        ")\n",
        "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
        "from sklearn.utils import shuffle\n",
        "import os\n",
        "import gdown"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Donwload images\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/u/0/uc?id=1TU2nTVGS2932hRs1u-ma4r3vmgqHRbMO\n",
            "To: c:\\Users\\Juliana\\Documents\\FGV\\8o\\Deep_Learning\\fgv-dl-assignment-2\\data.rar\n",
            "100%|██████████| 24.9M/24.9M [00:04<00:00, 5.67MB/s]\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "'data.rar'"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "url = 'https://drive.google.com/u/0/uc?id=1TU2nTVGS2932hRs1u-ma4r3vmgqHRbMO'\n",
        "output = 'data.rar'\n",
        "gdown.download(url, output, quiet=False)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "'unrar' n�o � reconhecido como um comando interno\n",
            "ou externo, um programa oper�vel ou um arquivo em lotes.\n"
          ]
        }
      ],
      "source": [
        "!unrar x data.rar"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oYZb1JUAHcUm"
      },
      "source": [
        "# Load images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [],
      "source": [
        "def load_tiff_image(path, grayscale=False):\n",
        "    image = Image.open(path)\n",
        "    image = image.convert(\"L\") if grayscale else image\n",
        "\n",
        "    return np.array(image)\n",
        "\n",
        "\n",
        "train_image = load_tiff_image(\"images/Images_Train/Image_Train.tif\")\n",
        "train_reference = load_tiff_image(\n",
        "    \"images/Images_Train/Reference_Train.tif\",\n",
        "    grayscale=True,\n",
        ")\n",
        "\n",
        "test_image = load_tiff_image(\"images/Images_Test/Image_Test.tif\")\n",
        "test_reference = load_tiff_image(\n",
        "    \"images/Images_Test/Reference_Test.tif\",\n",
        "    grayscale=True,\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [],
      "source": [
        "def one_hot_encode(image: np.ndarray):\n",
        "    W, H = image.shape\n",
        "    \n",
        "    colors = np.sort(np.unique(image))\n",
        "    image_encoded = np.zeros((W, H, len(colors)))\n",
        "\n",
        "    for i, color in enumerate(colors):\n",
        "        image_encoded[:, :, i] = image == color\n",
        "\n",
        "    return image_encoded\n",
        "\n",
        "train_reference_encoded = one_hot_encode(train_reference)\n",
        "test_reference_encoded = one_hot_encode(test_reference)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [],
      "source": [
        "def normalization(image: np.ndarray):\n",
        "    W, H, C = image.shape\n",
        "\n",
        "    scaler = MinMaxScaler(feature_range=(0, 1))\n",
        "    image_normalized = scaler.fit_transform(image.reshape((W * H), C))\n",
        "    image_normalized = image_normalized.reshape(W, H, C)\n",
        "\n",
        "    return image_normalized\n",
        "\n",
        "train_image_normalized = normalization(train_image)\n",
        "test_image_normalized = normalization(test_image)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OckMql719bbO"
      },
      "source": [
        "# **Define the functions**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "8SK7jWmG9Vpn"
      },
      "outputs": [],
      "source": [
        "def extract_patches(image, size, stride):\n",
        "    W, H, C = image.shape\n",
        "    patches = []\n",
        "\n",
        "    for i in range(0, W, stride):\n",
        "        for j in range(0, H, stride):\n",
        "            if i + size > W or j + size > H:\n",
        "                continue\n",
        "\n",
        "            patch = image[i : i + size, j : j + size]\n",
        "            patches.append(patch)\n",
        "\n",
        "    return np.array(patches).reshape(-1, size, size, C)\n",
        "\n",
        "\n",
        "def weighted_categorical_crossentropy(weights):\n",
        "    weights = K.variable(weights)\n",
        "\n",
        "    def loss(y_true, y_pred):\n",
        "        y_pred /= K.sum(y_pred, axis=-1, keepdims=True)\n",
        "        y_pred = K.clip(y_pred, K.epsilon(), 1 - K.epsilon())\n",
        "\n",
        "        loss = y_true * K.log(y_pred) + (1 - y_true) * K.log(1 - y_pred)\n",
        "        loss = -K.mean(loss * weights, -1)\n",
        "\n",
        "        return loss\n",
        "\n",
        "    return loss\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [],
      "source": [
        "def convolution_layers(layer, n_filters):\n",
        "    conv = Conv2D(n_filters, 3, padding=\"same\", activation=\"relu\")(layer)\n",
        "    conv = Conv2D(n_filters, 3, padding=\"same\", activation=\"relu\")(conv)\n",
        "    return conv\n",
        "\n",
        "\n",
        "def downsample_block(layer, n_filters):\n",
        "    conv = convolution_layers(layer, n_filters)\n",
        "    pool = MaxPool2D(2)(conv)\n",
        "    return conv, pool\n",
        "\n",
        "\n",
        "def upsample_block(layer, conv_features, n_filters):\n",
        "    layer = UpSampling2D(2)(layer)\n",
        "    layer = concatenate([layer, conv_features])\n",
        "    layer = convolution_layers(layer, n_filters)\n",
        "    return layer\n",
        "\n",
        "\n",
        "def unet(input_shape, n_classes):\n",
        "    print(input_shape)\n",
        "    in_layer = Input(input_shape)\n",
        "    n_layers = [16, 32, 64, 128, 256]\n",
        "\n",
        "    down_conv1, down_pool1 = downsample_block(in_layer, n_layers[0])\n",
        "    down_conv2, down_pool2 = downsample_block(down_pool1, n_layers[1])\n",
        "    down_conv3, down_pool3 = downsample_block(down_pool2, n_layers[2])\n",
        "    down_conv4, down_pool4 = downsample_block(down_pool3, n_layers[3])\n",
        "\n",
        "    middle_conv = convolution_layers(down_pool4, n_layers[4])\n",
        "\n",
        "    up_conv1 = upsample_block(middle_conv, down_conv4, n_layers[3])\n",
        "    up_conv2 = upsample_block(up_conv1, down_conv3, n_layers[2])\n",
        "    up_conv3 = upsample_block(up_conv2, down_conv2, n_layers[1])\n",
        "    up_conv4 = upsample_block(up_conv3, down_conv1, n_layers[0])\n",
        "\n",
        "    out_layer = Conv2D(n_classes, 1, padding=\"same\", activation=\"softmax\")(up_conv4)\n",
        "\n",
        "    return Model(in_layer, out_layer)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [],
      "source": [
        "def train_model(\n",
        "    model,\n",
        "    patches_train,\n",
        "    patches_tr_lb_h,\n",
        "    patches_val,\n",
        "    patches_val_lb_h,\n",
        "    batch_size,\n",
        "    epochs,\n",
        "):\n",
        "    print(\"Start training.. \")\n",
        "    for epoch in range(epochs):\n",
        "        loss_train = np.zeros((1, 2))\n",
        "        loss_val = np.zeros((1, 2))\n",
        "\n",
        "        # Computing the number of batchs\n",
        "        n_batches_train = patches_train.shape[0] // batch_size\n",
        "\n",
        "        # Random shuffle the data\n",
        "        patches_train, patches_tr_lb_h = shuffle(\n",
        "            patches_train, patches_tr_lb_h, random_state=0\n",
        "        )\n",
        "\n",
        "        # Training the network per batch\n",
        "        for batch in range(n_batches_train):\n",
        "            x_train_b = patches_train[\n",
        "                batch * batch_size : (batch + 1) * batch_size, :, :, :\n",
        "            ]\n",
        "            y_train_h_b = patches_tr_lb_h[\n",
        "                batch * batch_size : (batch + 1) * batch_size, :, :, :\n",
        "            ]\n",
        "            loss_train = loss_train + model.train_on_batch(x_train_b, y_train_h_b)\n",
        "\n",
        "        # Training loss\n",
        "        loss_train = loss_train / n_batches_train\n",
        "        print(\n",
        "            \"%d [Training loss: %f , Train acc.: %.2f%%]\"\n",
        "            % (epoch, loss_train[0, 0], 100 * loss_train[0, 1])\n",
        "        )\n",
        "\n",
        "        # Computing the number of batchs\n",
        "        n_batches_val = patches_val.shape[0] // batch_size\n",
        "\n",
        "        # Evaluating the model in the validation set\n",
        "        for batch in range(n_batches_val):\n",
        "            x_val_b = patches_val[\n",
        "                batch * batch_size : (batch + 1) * batch_size, :, :, :\n",
        "            ]\n",
        "            y_val_h_b = patches_val_lb_h[\n",
        "                batch * batch_size : (batch + 1) * batch_size, :, :, :\n",
        "            ]\n",
        "            loss_val = loss_val + model.test_on_batch(x_val_b, y_val_h_b)\n",
        "\n",
        "        # validation loss\n",
        "        loss_val = loss_val / n_batches_val\n",
        "        print(\n",
        "            \"%d [Validation loss: %f , Validation acc.: %.2f%%]\"\n",
        "            % (epoch, loss_val[0, 0], 100 * loss_val[0, 1])\n",
        "        )\n",
        "        # Add early stopping\n",
        "\n",
        "\n",
        "def test(model, patch_test):\n",
        "    result = model.predict(patch_test)\n",
        "    predicted_class = np.argmax(result, axis=-1)\n",
        "    return predicted_class\n",
        "\n",
        "\n",
        "def compute_metrics(true_labels, predicted_labels):\n",
        "    accuracy = 100 * accuracy_score(true_labels, predicted_labels)\n",
        "    f1score = 100 * f1_score(true_labels, predicted_labels, average=None)\n",
        "    recall = 100 * recall_score(true_labels, predicted_labels, average=None)\n",
        "    precision = 100 * precision_score(true_labels, predicted_labels, average=None)\n",
        "    return accuracy, f1score, recall, precision\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training set shape:   (2565, 1919, 3)\n",
            "Test set shape:       (2558, 2818, 3)\n",
            "Patch sizes:          [32, 64, 128]\n",
            "Validation split:     0.2\n",
            "Number of classes:    5\n",
            "Number of channels:   3\n",
            "Weights:              [0.17625794 0.3359289  0.25502094 0.00267358 0.23011864]\n"
          ]
        }
      ],
      "source": [
        "PATCH_SIZES = [32, 64, 128]\n",
        "VALIDATION_SPLIT = 0.2\n",
        "N_CHANNELS = train_image_normalized.shape[-1]\n",
        "N_CLASSES = train_reference_encoded.shape[-1]\n",
        "\n",
        "# weights are computed as the inverse of the frequency of each class in the training set\n",
        "WEIGHTS = np.array(\n",
        "    [\n",
        "        np.sum(train_reference_encoded[:, :, i] == 1)\n",
        "        for i in range(train_reference_encoded.shape[-1])\n",
        "    ]\n",
        ") / np.sum(train_reference_encoded == 1)\n",
        "\n",
        "print(\"Training set shape:  \", train_image_normalized.shape)\n",
        "print(\"Test set shape:      \", test_image_normalized.shape)\n",
        "print(\"Patch sizes:         \", PATCH_SIZES)\n",
        "print(\"Validation split:    \", VALIDATION_SPLIT)\n",
        "print(\"Number of classes:   \", N_CLASSES)\n",
        "print(\"Number of channels:  \", N_CHANNELS)\n",
        "print(\"Weights:             \", WEIGHTS)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 245
        },
        "id": "4osv4Y9DDTm7",
        "outputId": "44f9dd4a-cb67-4a7a-c77e-732be8a63431"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(32, 32, 3)\n",
            "Model: \"model_3\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                Output Shape                 Param #   Connected to                  \n",
            "==================================================================================================\n",
            " input_4 (InputLayer)        [(None, 32, 32, 3)]          0         []                            \n",
            "                                                                                                  \n",
            " conv2d_57 (Conv2D)          (None, 32, 32, 16)           448       ['input_4[0][0]']             \n",
            "                                                                                                  \n",
            " conv2d_58 (Conv2D)          (None, 32, 32, 16)           2320      ['conv2d_57[0][0]']           \n",
            "                                                                                                  \n",
            " max_pooling2d_12 (MaxPooli  (None, 16, 16, 16)           0         ['conv2d_58[0][0]']           \n",
            " ng2D)                                                                                            \n",
            "                                                                                                  \n",
            " conv2d_59 (Conv2D)          (None, 16, 16, 32)           4640      ['max_pooling2d_12[0][0]']    \n",
            "                                                                                                  \n",
            " conv2d_60 (Conv2D)          (None, 16, 16, 32)           9248      ['conv2d_59[0][0]']           \n",
            "                                                                                                  \n",
            " max_pooling2d_13 (MaxPooli  (None, 8, 8, 32)             0         ['conv2d_60[0][0]']           \n",
            " ng2D)                                                                                            \n",
            "                                                                                                  \n",
            " conv2d_61 (Conv2D)          (None, 8, 8, 64)             18496     ['max_pooling2d_13[0][0]']    \n",
            "                                                                                                  \n",
            " conv2d_62 (Conv2D)          (None, 8, 8, 64)             36928     ['conv2d_61[0][0]']           \n",
            "                                                                                                  \n",
            " max_pooling2d_14 (MaxPooli  (None, 4, 4, 64)             0         ['conv2d_62[0][0]']           \n",
            " ng2D)                                                                                            \n",
            "                                                                                                  \n",
            " conv2d_63 (Conv2D)          (None, 4, 4, 128)            73856     ['max_pooling2d_14[0][0]']    \n",
            "                                                                                                  \n",
            " conv2d_64 (Conv2D)          (None, 4, 4, 128)            147584    ['conv2d_63[0][0]']           \n",
            "                                                                                                  \n",
            " max_pooling2d_15 (MaxPooli  (None, 2, 2, 128)            0         ['conv2d_64[0][0]']           \n",
            " ng2D)                                                                                            \n",
            "                                                                                                  \n",
            " conv2d_65 (Conv2D)          (None, 2, 2, 256)            295168    ['max_pooling2d_15[0][0]']    \n",
            "                                                                                                  \n",
            " conv2d_66 (Conv2D)          (None, 2, 2, 256)            590080    ['conv2d_65[0][0]']           \n",
            "                                                                                                  \n",
            " up_sampling2d_4 (UpSamplin  (None, 4, 4, 256)            0         ['conv2d_66[0][0]']           \n",
            " g2D)                                                                                             \n",
            "                                                                                                  \n",
            " concatenate_12 (Concatenat  (None, 4, 4, 384)            0         ['up_sampling2d_4[0][0]',     \n",
            " e)                                                                  'conv2d_64[0][0]']           \n",
            "                                                                                                  \n",
            " conv2d_67 (Conv2D)          (None, 4, 4, 128)            442496    ['concatenate_12[0][0]']      \n",
            "                                                                                                  \n",
            " conv2d_68 (Conv2D)          (None, 4, 4, 128)            147584    ['conv2d_67[0][0]']           \n",
            "                                                                                                  \n",
            " up_sampling2d_5 (UpSamplin  (None, 8, 8, 128)            0         ['conv2d_68[0][0]']           \n",
            " g2D)                                                                                             \n",
            "                                                                                                  \n",
            " concatenate_13 (Concatenat  (None, 8, 8, 192)            0         ['up_sampling2d_5[0][0]',     \n",
            " e)                                                                  'conv2d_62[0][0]']           \n",
            "                                                                                                  \n",
            " conv2d_69 (Conv2D)          (None, 8, 8, 64)             110656    ['concatenate_13[0][0]']      \n",
            "                                                                                                  \n",
            " conv2d_70 (Conv2D)          (None, 8, 8, 64)             36928     ['conv2d_69[0][0]']           \n",
            "                                                                                                  \n",
            " up_sampling2d_6 (UpSamplin  (None, 16, 16, 64)           0         ['conv2d_70[0][0]']           \n",
            " g2D)                                                                                             \n",
            "                                                                                                  \n",
            " concatenate_14 (Concatenat  (None, 16, 16, 96)           0         ['up_sampling2d_6[0][0]',     \n",
            " e)                                                                  'conv2d_60[0][0]']           \n",
            "                                                                                                  \n",
            " conv2d_71 (Conv2D)          (None, 16, 16, 32)           27680     ['concatenate_14[0][0]']      \n",
            "                                                                                                  \n",
            " conv2d_72 (Conv2D)          (None, 16, 16, 32)           9248      ['conv2d_71[0][0]']           \n",
            "                                                                                                  \n",
            " up_sampling2d_7 (UpSamplin  (None, 32, 32, 32)           0         ['conv2d_72[0][0]']           \n",
            " g2D)                                                                                             \n",
            "                                                                                                  \n",
            " concatenate_15 (Concatenat  (None, 32, 32, 48)           0         ['up_sampling2d_7[0][0]',     \n",
            " e)                                                                  'conv2d_58[0][0]']           \n",
            "                                                                                                  \n",
            " conv2d_73 (Conv2D)          (None, 32, 32, 16)           6928      ['concatenate_15[0][0]']      \n",
            "                                                                                                  \n",
            " conv2d_74 (Conv2D)          (None, 32, 32, 16)           2320      ['conv2d_73[0][0]']           \n",
            "                                                                                                  \n",
            " conv2d_75 (Conv2D)          (None, 32, 32, 5)            85        ['conv2d_74[0][0]']           \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 1962693 (7.49 MB)\n",
            "Trainable params: 1962693 (7.49 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "__________________________________________________________________________________________________\n",
            "Start training.. \n",
            "0 [Training loss: 0.091686 , Train acc.: 50.88%]\n",
            "0 [Validation loss: 0.093111 , Validation acc.: 45.22%]\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[1;32m/home/juan/dev/juanbelieni/fgv-dl-assignment-2/main.ipynb Cell 13\u001b[0m line \u001b[0;36m3\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/juan/dev/juanbelieni/fgv-dl-assignment-2/main.ipynb#X15sZmlsZQ%3D%3D?line=27'>28</a>\u001b[0m model\u001b[39m.\u001b[39msummary()\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/juan/dev/juanbelieni/fgv-dl-assignment-2/main.ipynb#X15sZmlsZQ%3D%3D?line=28'>29</a>\u001b[0m model\u001b[39m.\u001b[39mcompile(loss\u001b[39m=\u001b[39mloss, optimizer\u001b[39m=\u001b[39madam, metrics\u001b[39m=\u001b[39m[\u001b[39m\"\u001b[39m\u001b[39maccuracy\u001b[39m\u001b[39m\"\u001b[39m])\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/juan/dev/juanbelieni/fgv-dl-assignment-2/main.ipynb#X15sZmlsZQ%3D%3D?line=30'>31</a>\u001b[0m train_model(\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/juan/dev/juanbelieni/fgv-dl-assignment-2/main.ipynb#X15sZmlsZQ%3D%3D?line=31'>32</a>\u001b[0m     model,\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/juan/dev/juanbelieni/fgv-dl-assignment-2/main.ipynb#X15sZmlsZQ%3D%3D?line=32'>33</a>\u001b[0m     train_image_patches,\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/juan/dev/juanbelieni/fgv-dl-assignment-2/main.ipynb#X15sZmlsZQ%3D%3D?line=33'>34</a>\u001b[0m     train_reference_patches,\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/juan/dev/juanbelieni/fgv-dl-assignment-2/main.ipynb#X15sZmlsZQ%3D%3D?line=34'>35</a>\u001b[0m     validation_image_patches,\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/juan/dev/juanbelieni/fgv-dl-assignment-2/main.ipynb#X15sZmlsZQ%3D%3D?line=35'>36</a>\u001b[0m     validation_reference_patches,\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/juan/dev/juanbelieni/fgv-dl-assignment-2/main.ipynb#X15sZmlsZQ%3D%3D?line=36'>37</a>\u001b[0m     batch_size\u001b[39m=\u001b[39;49m\u001b[39m32\u001b[39;49m,\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/juan/dev/juanbelieni/fgv-dl-assignment-2/main.ipynb#X15sZmlsZQ%3D%3D?line=37'>38</a>\u001b[0m     epochs\u001b[39m=\u001b[39;49m\u001b[39m100\u001b[39;49m,\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/juan/dev/juanbelieni/fgv-dl-assignment-2/main.ipynb#X15sZmlsZQ%3D%3D?line=38'>39</a>\u001b[0m )\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/juan/dev/juanbelieni/fgv-dl-assignment-2/main.ipynb#X15sZmlsZQ%3D%3D?line=40'>41</a>\u001b[0m \u001b[39m# # load the model\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/juan/dev/juanbelieni/fgv-dl-assignment-2/main.ipynb#X15sZmlsZQ%3D%3D?line=41'>42</a>\u001b[0m \u001b[39m# model = load_model(name)\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/juan/dev/juanbelieni/fgv-dl-assignment-2/main.ipynb#X15sZmlsZQ%3D%3D?line=42'>43</a>\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/juan/dev/juanbelieni/fgv-dl-assignment-2/main.ipynb#X15sZmlsZQ%3D%3D?line=50'>51</a>\u001b[0m \n\u001b[1;32m     <a href='vscode-notebook-cell:/home/juan/dev/juanbelieni/fgv-dl-assignment-2/main.ipynb#X15sZmlsZQ%3D%3D?line=51'>52</a>\u001b[0m \u001b[39m# # Plot the prediction (whole test image)\u001b[39;00m\n",
            "\u001b[1;32m/home/juan/dev/juanbelieni/fgv-dl-assignment-2/main.ipynb Cell 13\u001b[0m line \u001b[0;36m3\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/juan/dev/juanbelieni/fgv-dl-assignment-2/main.ipynb#X15sZmlsZQ%3D%3D?line=24'>25</a>\u001b[0m     x_train_b \u001b[39m=\u001b[39m patches_train[\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/juan/dev/juanbelieni/fgv-dl-assignment-2/main.ipynb#X15sZmlsZQ%3D%3D?line=25'>26</a>\u001b[0m         batch \u001b[39m*\u001b[39m batch_size : (batch \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m) \u001b[39m*\u001b[39m batch_size, :, :, :\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/juan/dev/juanbelieni/fgv-dl-assignment-2/main.ipynb#X15sZmlsZQ%3D%3D?line=26'>27</a>\u001b[0m     ]\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/juan/dev/juanbelieni/fgv-dl-assignment-2/main.ipynb#X15sZmlsZQ%3D%3D?line=27'>28</a>\u001b[0m     y_train_h_b \u001b[39m=\u001b[39m patches_tr_lb_h[\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/juan/dev/juanbelieni/fgv-dl-assignment-2/main.ipynb#X15sZmlsZQ%3D%3D?line=28'>29</a>\u001b[0m         batch \u001b[39m*\u001b[39m batch_size : (batch \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m) \u001b[39m*\u001b[39m batch_size, :, :, :\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/juan/dev/juanbelieni/fgv-dl-assignment-2/main.ipynb#X15sZmlsZQ%3D%3D?line=29'>30</a>\u001b[0m     ]\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/juan/dev/juanbelieni/fgv-dl-assignment-2/main.ipynb#X15sZmlsZQ%3D%3D?line=30'>31</a>\u001b[0m     loss_train \u001b[39m=\u001b[39m loss_train \u001b[39m+\u001b[39m model\u001b[39m.\u001b[39;49mtrain_on_batch(x_train_b, y_train_h_b)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/juan/dev/juanbelieni/fgv-dl-assignment-2/main.ipynb#X15sZmlsZQ%3D%3D?line=32'>33</a>\u001b[0m \u001b[39m# Training loss\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/juan/dev/juanbelieni/fgv-dl-assignment-2/main.ipynb#X15sZmlsZQ%3D%3D?line=33'>34</a>\u001b[0m loss_train \u001b[39m=\u001b[39m loss_train \u001b[39m/\u001b[39m n_batches_train\n",
            "File \u001b[0;32m~/.asdf/installs/python/3.11.0/lib/python3.11/site-packages/keras/src/engine/training.py:2684\u001b[0m, in \u001b[0;36mModel.train_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight, reset_metrics, return_dict)\u001b[0m\n\u001b[1;32m   2680\u001b[0m     iterator \u001b[39m=\u001b[39m data_adapter\u001b[39m.\u001b[39msingle_batch_iterator(\n\u001b[1;32m   2681\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdistribute_strategy, x, y, sample_weight, class_weight\n\u001b[1;32m   2682\u001b[0m     )\n\u001b[1;32m   2683\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtrain_function \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmake_train_function()\n\u001b[0;32m-> 2684\u001b[0m     logs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrain_function(iterator)\n\u001b[1;32m   2686\u001b[0m logs \u001b[39m=\u001b[39m tf_utils\u001b[39m.\u001b[39msync_to_numpy_or_python_type(logs)\n\u001b[1;32m   2687\u001b[0m \u001b[39mif\u001b[39;00m return_dict:\n",
            "File \u001b[0;32m~/.asdf/installs/python/3.11.0/lib/python3.11/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
            "File \u001b[0;32m~/.asdf/installs/python/3.11.0/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:825\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    822\u001b[0m compiler \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mxla\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mnonXla\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    824\u001b[0m \u001b[39mwith\u001b[39;00m OptionalXlaContext(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 825\u001b[0m   result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n\u001b[1;32m    827\u001b[0m new_tracing_count \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    828\u001b[0m without_tracing \u001b[39m=\u001b[39m (tracing_count \u001b[39m==\u001b[39m new_tracing_count)\n",
            "File \u001b[0;32m~/.asdf/installs/python/3.11.0/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:857\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    854\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n\u001b[1;32m    855\u001b[0m   \u001b[39m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[1;32m    856\u001b[0m   \u001b[39m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[0;32m--> 857\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_no_variable_creation_fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)  \u001b[39m# pylint: disable=not-callable\u001b[39;00m\n\u001b[1;32m    858\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_variable_creation_fn \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    859\u001b[0m   \u001b[39m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[1;32m    860\u001b[0m   \u001b[39m# in parallel.\u001b[39;00m\n\u001b[1;32m    861\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n",
            "File \u001b[0;32m~/.asdf/installs/python/3.11.0/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compiler.py:148\u001b[0m, in \u001b[0;36mTracingCompiler.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    145\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[1;32m    146\u001b[0m   (concrete_function,\n\u001b[1;32m    147\u001b[0m    filtered_flat_args) \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[0;32m--> 148\u001b[0m \u001b[39mreturn\u001b[39;00m concrete_function\u001b[39m.\u001b[39;49m_call_flat(\n\u001b[1;32m    149\u001b[0m     filtered_flat_args, captured_inputs\u001b[39m=\u001b[39;49mconcrete_function\u001b[39m.\u001b[39;49mcaptured_inputs)\n",
            "File \u001b[0;32m~/.asdf/installs/python/3.11.0/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py:1349\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, args, captured_inputs)\u001b[0m\n\u001b[1;32m   1345\u001b[0m possible_gradient_type \u001b[39m=\u001b[39m gradients_util\u001b[39m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1346\u001b[0m \u001b[39mif\u001b[39;00m (possible_gradient_type \u001b[39m==\u001b[39m gradients_util\u001b[39m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1347\u001b[0m     \u001b[39mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1348\u001b[0m   \u001b[39m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1349\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_build_call_outputs(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_inference_function(\u001b[39m*\u001b[39;49margs))\n\u001b[1;32m   1350\u001b[0m forward_backward \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1351\u001b[0m     args,\n\u001b[1;32m   1352\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1353\u001b[0m     executing_eagerly)\n\u001b[1;32m   1354\u001b[0m forward_function, args_with_tangents \u001b[39m=\u001b[39m forward_backward\u001b[39m.\u001b[39mforward()\n",
            "File \u001b[0;32m~/.asdf/installs/python/3.11.0/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:196\u001b[0m, in \u001b[0;36mAtomicFunction.__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    194\u001b[0m \u001b[39mwith\u001b[39;00m record\u001b[39m.\u001b[39mstop_recording():\n\u001b[1;32m    195\u001b[0m   \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_bound_context\u001b[39m.\u001b[39mexecuting_eagerly():\n\u001b[0;32m--> 196\u001b[0m     outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_bound_context\u001b[39m.\u001b[39;49mcall_function(\n\u001b[1;32m    197\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mname,\n\u001b[1;32m    198\u001b[0m         \u001b[39mlist\u001b[39;49m(args),\n\u001b[1;32m    199\u001b[0m         \u001b[39mlen\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfunction_type\u001b[39m.\u001b[39;49mflat_outputs),\n\u001b[1;32m    200\u001b[0m     )\n\u001b[1;32m    201\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    202\u001b[0m     outputs \u001b[39m=\u001b[39m make_call_op_in_graph(\u001b[39mself\u001b[39m, \u001b[39mlist\u001b[39m(args))\n",
            "File \u001b[0;32m~/.asdf/installs/python/3.11.0/lib/python3.11/site-packages/tensorflow/python/eager/context.py:1457\u001b[0m, in \u001b[0;36mContext.call_function\u001b[0;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[1;32m   1455\u001b[0m cancellation_context \u001b[39m=\u001b[39m cancellation\u001b[39m.\u001b[39mcontext()\n\u001b[1;32m   1456\u001b[0m \u001b[39mif\u001b[39;00m cancellation_context \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m-> 1457\u001b[0m   outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39;49mexecute(\n\u001b[1;32m   1458\u001b[0m       name\u001b[39m.\u001b[39;49mdecode(\u001b[39m\"\u001b[39;49m\u001b[39mutf-8\u001b[39;49m\u001b[39m\"\u001b[39;49m),\n\u001b[1;32m   1459\u001b[0m       num_outputs\u001b[39m=\u001b[39;49mnum_outputs,\n\u001b[1;32m   1460\u001b[0m       inputs\u001b[39m=\u001b[39;49mtensor_inputs,\n\u001b[1;32m   1461\u001b[0m       attrs\u001b[39m=\u001b[39;49mattrs,\n\u001b[1;32m   1462\u001b[0m       ctx\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m,\n\u001b[1;32m   1463\u001b[0m   )\n\u001b[1;32m   1464\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1465\u001b[0m   outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m   1466\u001b[0m       name\u001b[39m.\u001b[39mdecode(\u001b[39m\"\u001b[39m\u001b[39mutf-8\u001b[39m\u001b[39m\"\u001b[39m),\n\u001b[1;32m   1467\u001b[0m       num_outputs\u001b[39m=\u001b[39mnum_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1471\u001b[0m       cancellation_manager\u001b[39m=\u001b[39mcancellation_context,\n\u001b[1;32m   1472\u001b[0m   )\n",
            "File \u001b[0;32m~/.asdf/installs/python/3.11.0/lib/python3.11/site-packages/tensorflow/python/eager/execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m     52\u001b[0m   ctx\u001b[39m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 53\u001b[0m   tensors \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39;49mTFE_Py_Execute(ctx\u001b[39m.\u001b[39;49m_handle, device_name, op_name,\n\u001b[1;32m     54\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[1;32m     55\u001b[0m \u001b[39mexcept\u001b[39;00m core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     56\u001b[0m   \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "\n",
        "\n",
        "\n",
        "for size in PATCH_SIZES:\n",
        "    # # Extract training patches\n",
        "    train_image_patches = extract_patches(train_image_normalized, size, size)\n",
        "    train_reference_patches = extract_patches(train_reference_encoded, size, size)\n",
        "\n",
        "    # Split the training patches into training and validation sets\n",
        "    train_image_patches, train_reference_patches = shuffle(\n",
        "        train_image_patches, train_reference_patches, random_state=0\n",
        "    )\n",
        "\n",
        "    train_size = int(train_image_patches.shape[0] * (1 - VALIDATION_SPLIT))\n",
        "    validation_size = int(train_image_patches.shape[0] * VALIDATION_SPLIT)\n",
        "\n",
        "    train_image_patches, validation_image_patches = (\n",
        "        train_image_patches[:train_size],\n",
        "        train_image_patches[train_size:],\n",
        "    )\n",
        "\n",
        "    train_reference_patches, validation_reference_patches = (\n",
        "        train_reference_patches[:train_size],\n",
        "        train_reference_patches[train_size:],\n",
        "    )\n",
        "\n",
        "    # # Train the model\n",
        "    adam = Adam(lr=0.0001, beta_1=0.9)\n",
        "    model = unet((size, size, N_CHANNELS), N_CLASSES)\n",
        "    loss = weighted_categorical_crossentropy(WEIGHTS)\n",
        "    model.summary()\n",
        "    model.compile(loss=loss, optimizer=adam, metrics=[\"accuracy\"])\n",
        "\n",
        "    train_model(\n",
        "        model,\n",
        "        train_image_patches,\n",
        "        train_reference_patches,\n",
        "        validation_image_patches,\n",
        "        validation_reference_patches,\n",
        "        batch_size=32,\n",
        "        epochs=100,\n",
        "    )\n",
        "\n",
        "    # # load the model\n",
        "    # model = load_model(name)\n",
        "\n",
        "    # Train the model\n",
        "\n",
        "    # # Test the model\n",
        "    # predicted_labels = test(model, patch_test)\n",
        "\n",
        "    # # Metrics\n",
        "    # compute_metrics(true_labels, predicted_labels)\n",
        "\n",
        "    # # Plot the prediction (whole test image)\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
